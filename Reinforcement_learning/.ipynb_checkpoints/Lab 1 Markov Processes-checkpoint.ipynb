{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1]\n",
      " [-2]\n",
      " [-2]\n",
      " [-2]\n",
      " [ 1]\n",
      " [10]\n",
      " [ 0]]\n"
     ]
    }
   ],
   "source": [
    "'''1. Choose simple code representation of the S state \n",
    "space and implement it'''\n",
    "States = [('Facebook',-1), ('Class 1',-2), ('Class 2',-2), ('Class 3',-2), \n",
    "          ('Pub',1), ('Pass',10), ('Sleep',0)]\n",
    "# Return States in format for matrix multiplication\n",
    "S = np.array([i[1] for i in States]).reshape(n, 1)\n",
    "n = len(States)\n",
    "gamma = 0.5\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''2. Write a funciton that returns the state transition probability \n",
    "Psisj'''\n",
    "# Note the below means the probability of transitioning FROM state s\n",
    "# TO state'\n",
    "def state_transitions(i):\n",
    "    s_ts = np.array([\n",
    "        np.array([0.9, 0.1, 0, 0, 0, 0, 0]),\n",
    "        np.array([0.5, 0, 0.5, 0, 0, 0, 0]),\n",
    "        np.array([0, 0, 0, 0.8, 0, 0, 0.2]),\n",
    "        np.array([0, 0, 0, 0, 0.6, 0.4, 0]),\n",
    "        np.array([0, 0, 0, 0, 0, 0, 1]),\n",
    "        np.array([0, 0.2, 0.4, 0.4, 0, 0, 0]),\n",
    "        np.array([0, 0, 0, 0, 0, 0, 1])\n",
    "    ])\n",
    "    return s_ts[i]\n",
    "\n",
    "state_transitions(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''3. Write a function that gives you Rs (note that in our \n",
    "MRP the reward is deterministic, so the expectation is the\n",
    "immediate reward)'''\n",
    "def reward(i):\n",
    "    # Returns immediate expected reward in state i\n",
    "    r = gamma * state_transitions(i).reshape(1,n) @ S\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2.220425831996708,\n",
       " -2.0256641046478108,\n",
       " -0.10282558237704506,\n",
       " 4.314005603285287,\n",
       " 0.0,\n",
       " -1.3046297181710906,\n",
       " 0.0]"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''4. Sample a trace (the sequence of state, reward, state, reward\n",
    ",..., terminal state, 0) from this MRP. \n",
    "Hint: you need to write \n",
    "functions that e.g. imnplement the probabilistic state transition \n",
    "dynamics. Simulate a run of the MRP always using Class1 as the only\n",
    "initial state.'''\n",
    "# s_t = 1\n",
    "def trace(s_t):\n",
    "    journey = []\n",
    "    while s_t != 6:\n",
    "        # Get next state\n",
    "        s_t = int(np.random.choice(n, 1, p = state_transitions(s_t)))\n",
    "        # Compute reward at next state\n",
    "        r_t = int(S[s_t])\n",
    "        # Save reward and state\n",
    "        journey.append((s_t, r_t))\n",
    "    return journey\n",
    "\n",
    "'''5. Write a function that computes the return of a specific trace \n",
    "(i.e. from its initial state till it reaches the terminal state).'''\n",
    "def expec_reward(journey):\n",
    "    rs = [j[1] * gamma**n for n,j in enumerate(journey)]\n",
    "    return sum(rs)\n",
    "\n",
    "# '''6. Write a function that computes (by averaging over the returns \n",
    "# of many sampled traces) the value of each state in our MRP. \n",
    "# This is a way of computing the state value function (Why?)'''\n",
    "\n",
    "def compute_state_value_fn(samples):\n",
    "    avg_rewards = []\n",
    "    for s_t in range(n):\n",
    "        rewards = [expec_reward(trace(s_t)) for i in range(samples)]\n",
    "        avg_rewards.append(sum(rewards)/samples)\n",
    "    return avg_rewards\n",
    "\n",
    "compute_state_value_fn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
