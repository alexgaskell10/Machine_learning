{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Basic code to specify an MDP\n",
    "#   Learning in Autonomous Systems coursework\n",
    "#   Aldo Faisal (2015), Imperial College London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StairClimbingMDP(object):\n",
    "    def __init__(self):\n",
    "        # States are:  { s1 <-- s2 <=> s3 <=> s4 <=> s5 <=> s6 --> s7 ]\n",
    "        self.S = 7\n",
    "        self.state_names = ['s1', 's2', 's3', 's4', 's5', 's6', 's7']\n",
    "\n",
    "        # Actions are: {L,R} --> {0, 1}\n",
    "        self.A = 2\n",
    "        self.action_names = ['L','R']\n",
    "\n",
    "        # Matrix indicating absorbing states\n",
    "        # P  1   2   3   4   5  6  7  G   <-- STATES \n",
    "        self.absorbing = [1, 0, 0, 0, 0, 0, 1]\n",
    "\n",
    "        # Load transition\n",
    "        self.T = self.transition_matrix()\n",
    "\n",
    "        # Load reward matrix\n",
    "        self.R = self.reward_matrix()\n",
    "    \n",
    "    # get the transition matrix\n",
    "    def transition_matrix(self):\n",
    "        # MODIFY HERE\n",
    "        #               1    ...    7 <-- FROM STATE\n",
    "        TL = np.array([[0,0,0,0,0,0,0],   # 1 TO STATE\n",
    "                       [0,0,0,0,0,0,0],   # .\n",
    "                       [0,0,0,0,0,0,0],   # .\n",
    "                       [0,0,0,0,0,0,0],   #\n",
    "                       [0,0,0,0,0,0,0],   # \n",
    "                       [0,0,0,0,0,0,0],   # \n",
    "                       [0,0,0,0,0,0,0]])  # 7\n",
    "\n",
    "\n",
    "        # MODIFY HERE\n",
    "        #               1    ...    7 <-- FROM STATE\n",
    "        TR = np.array([[0,0,0,0,0,0,0],   # 1 TO STATE\n",
    "                       [0,0,0,0,0,0,0],   # \n",
    "                       [0,0,0,0,0,0,0],   # . \n",
    "                       [0,0,0,0,0,0,0],   # .\n",
    "                       [0,0,0,0,0,0,0],   # .\n",
    "                       [0,0,0,0,0,0,0],   #\n",
    "                       [0,0,0,0,0,0,0]])  # 7\n",
    "\n",
    "\n",
    "        return np.dstack([TL,TR]) # transition probabilities for each action \n",
    "\n",
    "    \n",
    "    # the transition subfunction\n",
    "    def transition_function(prior_state, action, post_state):\n",
    "        # Reward function (defined locally)\n",
    "        prob = self.T(post_state,prior_state, action)\n",
    "        return prob\n",
    "\n",
    "    \n",
    "    \n",
    "    # get the reward matrix\n",
    "    def reward_matrix(self, S = None, A = None):\n",
    "        # i.e. 11x11 matrix of rewards for being in state s,\n",
    "        # performing action a and ending in state s'\n",
    "\n",
    "        if(S == None):\n",
    "            S = self.S\n",
    "        if(A == None):\n",
    "            A = self.A\n",
    "        \n",
    "        R = np.zeros((S,S,A))\n",
    "\n",
    "        for i in range(S):\n",
    "            for j in range(A):\n",
    "                for k in range(S):\n",
    "                    R[k,i,j] = self.reward_function(i,j,k)\n",
    "\n",
    "        return R\n",
    "    \n",
    "    # the locally defined reward function\n",
    "    def reward_function(self,prior_state, action, post_state):\n",
    "        # reward function (defined locally)\n",
    "        # MODIFY HERE\n",
    "        if ((prior_state == 1) and (action == 0) and (post_state == 0)):\n",
    "            rew = -1\n",
    "        elif ((prior_state == 5) and (action == 1) and (post_state == 6)):\n",
    "            rew = 1\n",
    "        elif (action == 0):\n",
    "            rew = 0\n",
    "        else:\n",
    "            rew = 0\n",
    "\n",
    "        return rew\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.StairClimbingMDP at 0x10769b358>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StairClimbingMDP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
